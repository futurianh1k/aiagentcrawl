"""
3íšŒì°¨ ì‹¤ìŠµ 08: LangGraph Conditional Routing
í˜ì´ì§€ 21 - ëŒ“ê¸€ ìˆ˜ ê¸°ì¤€ ë¶„ê¸° ë¼ìš°íŒ…

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” LangGraphì˜ ì¡°ê±´ë¶€ ë¼ìš°íŒ…ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
- ì¡°ê±´ë¶€ ë¶„ê¸° (Conditional Edge)
- ëŒ“ê¸€ ìˆ˜ì— ë”°ë¥¸ ë°°ì¹˜/ì‹¤ì‹œê°„ ë¶„ì„ ì„ íƒ
- ë™ì  ì›Œí¬í”Œë¡œìš° ì œì–´
- ì„±ëŠ¥ ìµœì í™” ì „ëµ
"""

import os
from typing import TypedDict, List, Dict, Any
from datetime import datetime

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class ConditionalAgentState(TypedDict):
    """ì¡°ê±´ë¶€ ë¼ìš°íŒ…ìš© ìƒíƒœ"""
    keyword: str
    articles: List[Dict[str, Any]]
    total_comments: int
    processing_mode: str  # "batch" ë˜ëŠ” "realtime"

    # ë¶„ì„ ê²°ê³¼
    analysis_results: List[Dict[str, Any]]
    processing_stats: Dict[str, Any]

    # ë©”íƒ€ë°ì´í„°
    workflow_path: List[str]  # ì‹¤í–‰ëœ ë…¸ë“œ ê²½ë¡œ
    decision_reasons: List[str]  # ë¶„ê¸° ê²°ì • ì´ìœ 
    errors: List[str]

def setup_llm():
    """LLM ì´ˆê¸°í™”"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    return ChatOpenAI(model="gpt-4", temperature=0.3, api_key=api_key)

def data_validator(state: ConditionalAgentState) -> ConditionalAgentState:
    """ë°ì´í„° ê²€ì¦ Agent"""
    print("ğŸ” Data Validator ì‹¤í–‰: ì…ë ¥ ë°ì´í„° ê²€ì¦")

    state["workflow_path"].append("validator")

    # ëª¨ì˜ ê¸°ì‚¬ ë°ì´í„° ìƒì„± (ëŒ“ê¸€ ìˆ˜ê°€ ë‹¤ë¥¸ ê¸°ì‚¬ë“¤)
    mock_articles = [
        {
            "title": f"{state['keyword']} ëŒ€ê·œëª¨ ì—…ë°ì´íŠ¸",
            "comments": [f"ëŒ“ê¸€ {i}" for i in range(150)]  # 150ê°œ ëŒ“ê¸€
        },
        {
            "title": f"{state['keyword']} ì†Œì‹", 
            "comments": [f"ëŒ“ê¸€ {i}" for i in range(5)]   # 5ê°œ ëŒ“ê¸€
        },
        {
            "title": f"{state['keyword']} ë¶„ì„",
            "comments": [f"ëŒ“ê¸€ {i}" for i in range(200)]  # 200ê°œ ëŒ“ê¸€
        }
    ]

    state["articles"] = mock_articles

    # ì´ ëŒ“ê¸€ ìˆ˜ ê³„ì‚°
    total_comments = sum(len(article["comments"]) for article in state["articles"])
    state["total_comments"] = total_comments

    print(f"âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {len(state['articles'])}ê°œ ê¸°ì‚¬, {total_comments}ê°œ ëŒ“ê¸€")

    return state

def should_use_batch_processing(state: ConditionalAgentState) -> str:
    """ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ë°°ì¹˜ ì²˜ë¦¬ ì—¬ë¶€ ê²°ì •"""

    threshold = 100  # ëŒ“ê¸€ 100ê°œ ê¸°ì¤€
    total_comments = state["total_comments"]

    if total_comments > threshold:
        decision = "batch_analyzer"
        reason = f"ì´ {total_comments}ê°œ ëŒ“ê¸€ > {threshold}ê°œ ê¸°ì¤€, ë°°ì¹˜ ì²˜ë¦¬ ì„ íƒ"
        state["processing_mode"] = "batch"
    else:
        decision = "realtime_analyzer"
        reason = f"ì´ {total_comments}ê°œ ëŒ“ê¸€ â‰¤ {threshold}ê°œ ê¸°ì¤€, ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„ íƒ"
        state["processing_mode"] = "realtime"

    state["decision_reasons"].append(reason)

    print(f"ğŸ”€ ë¼ìš°íŒ… ê²°ì •: {decision}")
    print(f"ğŸ“‹ ê²°ì • ê·¼ê±°: {reason}")

    return decision

def realtime_analyzer(state: ConditionalAgentState) -> ConditionalAgentState:
    """ì‹¤ì‹œê°„ ê°ì„± ë¶„ì„ Agent"""
    print("âš¡ Realtime Analyzer ì‹¤í–‰: ìˆœì°¨ ì²˜ë¦¬")

    state["workflow_path"].append("realtime_analyzer")
    start_time = datetime.now()

    try:
        llm = setup_llm()
        analysis_results = []

        for article in state["articles"]:
            article_analysis = {
                "title": article["title"],
                "comment_count": len(article["comments"]),
                "sentiments": [],
                "processing_method": "realtime"
            }

            print(f"  ğŸ“° ì‹¤ì‹œê°„ ë¶„ì„: {article['title']} ({len(article['comments'])}ê°œ ëŒ“ê¸€)")

            # ê° ëŒ“ê¸€ì„ ê°œë³„ì ìœ¼ë¡œ ì¦‰ì‹œ ì²˜ë¦¬
            for i, comment in enumerate(article["comments"]):
                # ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ì„
                if any(word in comment.lower() for word in ["ì¢‹", "í›Œë¥­", "ìµœê³ "]):
                    sentiment = "ê¸ì •"
                elif any(word in comment.lower() for word in ["ë‚˜ì˜", "ìµœì•…", "ì‹¤ë§"]):
                    sentiment = "ë¶€ì •"
                else:
                    sentiment = "ì¤‘ë¦½"

                article_analysis["sentiments"].append({
                    "comment_index": i,
                    "sentiment": sentiment,
                    "processing_time": 0.001  # ë¹ ë¥¸ ì²˜ë¦¬
                })

            analysis_results.append(article_analysis)

        processing_time = (datetime.now() - start_time).total_seconds()

        state["analysis_results"] = analysis_results
        state["processing_stats"] = {
            "method": "realtime",
            "total_processing_time": processing_time,
            "comments_per_second": state["total_comments"] / processing_time if processing_time > 0 else 0,
            "advantages": ["ì¦‰ì‹œ ê²°ê³¼ í™•ì¸", "ë©”ëª¨ë¦¬ íš¨ìœ¨ì ", "ì¤‘ê°„ ê²°ê³¼ í™œìš© ê°€ëŠ¥"]
        }

        print(f"âœ… ì‹¤ì‹œê°„ ë¶„ì„ ì™„ë£Œ: {state['total_comments']}ê°œ ëŒ“ê¸€, {processing_time:.2f}ì´ˆ")

    except Exception as e:
        print(f"âŒ ì‹¤ì‹œê°„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        state["errors"].append(f"Realtime Analyzer: {str(e)}")

    return state

def batch_analyzer(state: ConditionalAgentState) -> ConditionalAgentState:
    """ë°°ì¹˜ ê°ì„± ë¶„ì„ Agent"""
    print("ğŸ“¦ Batch Analyzer ì‹¤í–‰: ë°°ì¹˜ ì²˜ë¦¬")

    state["workflow_path"].append("batch_analyzer")
    start_time = datetime.now()

    try:
        llm = setup_llm()
        analysis_results = []

        # ëª¨ë“  ëŒ“ê¸€ì„ ëª¨ì•„ì„œ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        all_comments = []
        comment_mapping = []  # ëŒ“ê¸€ê³¼ ê¸°ì‚¬ ë§¤í•‘ ì •ë³´

        for article_idx, article in enumerate(state["articles"]):
            for comment_idx, comment in enumerate(article["comments"]):
                all_comments.append(comment)
                comment_mapping.append({
                    "article_idx": article_idx,
                    "comment_idx": comment_idx,
                    "article_title": article["title"]
                })

        print(f"  ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì¤€ë¹„: ì´ {len(all_comments)}ê°œ ëŒ“ê¸€")

        # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (ì‹¤ì œë¡œëŠ” LLM Batch API ì‚¬ìš©)
        batch_size = 50
        batch_results = []

        for i in range(0, len(all_comments), batch_size):
            batch = all_comments[i:i + batch_size]
            print(f"    ë°°ì¹˜ {i//batch_size + 1}: {len(batch)}ê°œ ëŒ“ê¸€ ì²˜ë¦¬")

            # ë°°ì¹˜ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ LLM í˜¸ì¶œ)
            for comment in batch:
                if any(word in comment.lower() for word in ["ì¢‹", "í›Œë¥­", "ìµœê³ "]):
                    sentiment = "ê¸ì •"
                elif any(word in comment.lower() for word in ["ë‚˜ì˜", "ìµœì•…", "ì‹¤ë§"]):
                    sentiment = "ë¶€ì •" 
                else:
                    sentiment = "ì¤‘ë¦½"

                batch_results.append({
                    "comment": comment,
                    "sentiment": sentiment,
                    "batch_processed": True
                })

        # ê²°ê³¼ë¥¼ ê¸°ì‚¬ë³„ë¡œ ì¬êµ¬ì„±
        for article_idx, article in enumerate(state["articles"]):
            article_analysis = {
                "title": article["title"],
                "comment_count": len(article["comments"]),
                "sentiments": [],
                "processing_method": "batch"
            }

            # í•´ë‹¹ ê¸°ì‚¬ì˜ ëŒ“ê¸€ ê²°ê³¼ë§Œ ì¶”ì¶œ
            for mapping, result in zip(comment_mapping, batch_results):
                if mapping["article_idx"] == article_idx:
                    article_analysis["sentiments"].append({
                        "comment_index": mapping["comment_idx"],
                        "sentiment": result["sentiment"],
                        "batch_processed": True
                    })

            analysis_results.append(article_analysis)

        processing_time = (datetime.now() - start_time).total_seconds()

        state["analysis_results"] = analysis_results
        state["processing_stats"] = {
            "method": "batch",
            "total_processing_time": processing_time,
            "comments_per_second": state["total_comments"] / processing_time if processing_time > 0 else 0,
            "batch_size": batch_size,
            "total_batches": len(range(0, len(all_comments), batch_size)),
            "advantages": ["ë†’ì€ ì²˜ë¦¬ëŸ‰", "ë¹„ìš© íš¨ìœ¨ì ", "ì¼ê´€ëœ í’ˆì§ˆ"]
        }

        print(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {state['total_comments']}ê°œ ëŒ“ê¸€, {processing_time:.2f}ì´ˆ")

    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
        state["errors"].append(f"Batch Analyzer: {str(e)}")

    return state

def results_aggregator(state: ConditionalAgentState) -> ConditionalAgentState:
    """ê²°ê³¼ ì§‘ê³„ Agent"""
    print("ğŸ“ˆ Results Aggregator ì‹¤í–‰: ê²°ê³¼ ì§‘ê³„ ë° ìš”ì•½")

    state["workflow_path"].append("aggregator")

    try:
        # ì „ì²´ ê°ì„± ë¶„í¬ ê³„ì‚°
        all_sentiments = []
        for article_analysis in state["analysis_results"]:
            for sentiment_data in article_analysis["sentiments"]:
                all_sentiments.append(sentiment_data["sentiment"])

        sentiment_counts = {}
        for sentiment in all_sentiments:
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1

        # ì²˜ë¦¬ ë°©ì‹ë³„ ì„±ëŠ¥ ë¹„êµ
        processing_method = state["processing_stats"]["method"]
        processing_time = state["processing_stats"]["total_processing_time"]
        throughput = state["processing_stats"]["comments_per_second"]

        summary_report = f"""
ğŸ¯ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë¶„ì„ ê²°ê³¼
{'=' * 50}

ğŸ”€ ì›Œí¬í”Œë¡œìš° ê²½ë¡œ: {' â†’ '.join(state['workflow_path'])}

ğŸ“Š ì²˜ë¦¬ í†µê³„:
- ì„ íƒëœ ë°©ì‹: {processing_method.upper()}
- ì´ ëŒ“ê¸€ ìˆ˜: {state['total_comments']}ê°œ
- ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ
- ì²˜ë¦¬ëŸ‰: {throughput:.1f} ëŒ“ê¸€/ì´ˆ

ğŸ“‹ ë¶„ê¸° ê²°ì • ê³¼ì •:
"""

        for reason in state["decision_reasons"]:
            summary_report += f"- {reason}\n"

        summary_report += f"""
ğŸ“ˆ ê°ì„± ë¶„í¬:
- ê¸ì •: {sentiment_counts.get('ê¸ì •', 0)}ê°œ ({sentiment_counts.get('ê¸ì •', 0)/len(all_sentiments)*100:.1f}%)
- ë¶€ì •: {sentiment_counts.get('ë¶€ì •', 0)}ê°œ ({sentiment_counts.get('ë¶€ì •', 0)/len(all_sentiments)*100:.1f}%)
- ì¤‘ë¦½: {sentiment_counts.get('ì¤‘ë¦½', 0)}ê°œ ({sentiment_counts.get('ì¤‘ë¦½', 0)/len(all_sentiments)*100:.1f}%)

ğŸš€ {processing_method.title()} ì²˜ë¦¬ì˜ ì¥ì :
"""

        for advantage in state["processing_stats"]["advantages"]:
            summary_report += f"- {advantage}\n"

        state["processing_stats"]["summary_report"] = summary_report
        state["processing_stats"]["sentiment_distribution"] = sentiment_counts

        print(f"âœ… ê²°ê³¼ ì§‘ê³„ ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì§‘ê³„ ì˜¤ë¥˜: {e}")
        state["errors"].append(f"Aggregator: {str(e)}")

    return state

def create_conditional_workflow():
    """ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš° ìƒì„±"""

    workflow = StateGraph(ConditionalAgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("validator", data_validator)
    workflow.add_node("realtime_analyzer", realtime_analyzer)
    workflow.add_node("batch_analyzer", batch_analyzer)
    workflow.add_node("aggregator", results_aggregator)

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("validator")

    # ì¡°ê±´ë¶€ ë¶„ê¸° (í•µì‹¬!)
    workflow.add_conditional_edges(
        "validator",                    # ë¶„ê¸° ì‹œì‘ ë…¸ë“œ
        should_use_batch_processing,    # ë¶„ê¸° ê²°ì • í•¨ìˆ˜
        {
            "realtime_analyzer": "realtime_analyzer",  # ì‹¤ì‹œê°„ ì²˜ë¦¬ ê²½ë¡œ
            "batch_analyzer": "batch_analyzer"         # ë°°ì¹˜ ì²˜ë¦¬ ê²½ë¡œ
        }
    )

    # ë‘ ê²½ë¡œ ëª¨ë‘ ì§‘ê³„ê¸°ë¡œ ìˆ˜ë ´
    workflow.add_edge("realtime_analyzer", "aggregator")
    workflow.add_edge("batch_analyzer", "aggregator")
    workflow.add_edge("aggregator", END)

    return workflow.compile()

if __name__ == "__main__":
    print("ğŸš€ LangGraph Conditional Routing ì‹¤ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    print("=" * 70)

    try:
        # 1. ì›Œí¬í”Œë¡œìš° ìƒì„±
        app = create_conditional_workflow()
        print("âœ… ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš° ìƒì„± ì™„ë£Œ")

        # 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
        test_cases = [
            {"keyword": "AIê¸°ìˆ ", "description": "ì†ŒëŸ‰ ëŒ“ê¸€ (ì‹¤ì‹œê°„ ì²˜ë¦¬ ì˜ˆìƒ)"},
            {"keyword": "ê²½ì œì •ì±…", "description": "ëŒ€ëŸ‰ ëŒ“ê¸€ (ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆìƒ)"}
        ]

        for i, test_case in enumerate(test_cases, 1):
            print(f"\n{'='*20} í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i} {'='*20}")
            print(f"ğŸ¯ í‚¤ì›Œë“œ: {test_case['keyword']}")
            print(f"ğŸ“ ì„¤ëª…: {test_case['description']}")

            # ì´ˆê¸° ìƒíƒœ
            initial_state: ConditionalAgentState = {
                "keyword": test_case["keyword"],
                "articles": [],
                "total_comments": 0,
                "processing_mode": "",
                "analysis_results": [],
                "processing_stats": {},
                "workflow_path": [],
                "decision_reasons": [],
                "errors": []
            }

            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            final_state = app.invoke(initial_state)

            # ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
            print(f"   ğŸ”€ ì›Œí¬í”Œë¡œìš° ê²½ë¡œ: {' â†’ '.join(final_state['workflow_path'])}")
            print(f"   âš™ï¸ ì„ íƒëœ ì²˜ë¦¬ ë°©ì‹: {final_state['processing_mode']}")
            print(f"   ğŸ’¬ ì´ ëŒ“ê¸€ ìˆ˜: {final_state['total_comments']}ê°œ")

            if final_state["processing_stats"]:
                stats = final_state["processing_stats"]
                print(f"   â±ï¸ ì²˜ë¦¬ ì‹œê°„: {stats.get('total_processing_time', 0):.2f}ì´ˆ")
                print(f"   ğŸš€ ì²˜ë¦¬ëŸ‰: {stats.get('comments_per_second', 0):.1f} ëŒ“ê¸€/ì´ˆ")

            # ìš”ì•½ ë¦¬í¬íŠ¸ ì¶œë ¥
            if "summary_report" in final_state.get("processing_stats", {}):
                print(final_state["processing_stats"]["summary_report"])

        print("\nâœ… LangGraph Conditional Routing ì‹¤ìŠµ ì™„ë£Œ!")
        print("\nğŸ’¡ í•µì‹¬ ê°œë…:")
        print("   1. Conditional Edge: ì¡°ê±´ì— ë”°ë¥¸ ë™ì  ë¼ìš°íŒ…")
        print("   2. Decision Function: ë¶„ê¸° ê²°ì • ë¡œì§") 
        print("   3. Multi-Path Convergence: ì—¬ëŸ¬ ê²½ë¡œê°€ í•˜ë‚˜ë¡œ ìˆ˜ë ´")
        print("   4. Performance Optimization: ìƒí™©ë³„ ìµœì  ì²˜ë¦¬ ë°©ì‹")
        print("\nğŸ“š ë‹¤ìŒ ë‹¨ê³„:")
        print("   - 09_langchain_memory.py: ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬")
        print("   - 10_integrated_demo.py: ì „ì²´ ê¸°ëŠ¥ í†µí•©")

    except Exception as e:
        print(f"âŒ ì‹¤ìŠµ ì˜¤ë¥˜: {e}")
        print("\nğŸ”§ í•´ê²° ë°©ë²•:")
        print("   1. OpenAI API í‚¤ í™•ì¸")
        print("   2. pip install langgraph langchain-openai")
        print("   3. ì¡°ê±´ í•¨ìˆ˜ ë°˜í™˜ê°’ í™•ì¸")

"""
3íšŒì°¨ ì‹¤ìŠµ 01: OpenAI API ê¸°ì´ˆ
í˜ì´ì§€ 6 - Chat Completions API ì‚¬ìš©ë²•

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” OpenAI Chat Completions APIì˜ ê¸°ë³¸ ì‚¬ìš©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.
- API í‚¤ ì„¤ì •
- ê¸°ë³¸ Chat Completions í˜¸ì¶œ
- ëª¨ë¸ ì„ íƒ (GPT-4 vs GPT-3.5-turbo)
- ì˜¨ë„, ë§¥ìŠ¤ í† í° ë“± íŒŒë¼ë¯¸í„° ì¡°ì •
"""

import os
from openai import OpenAI
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def setup_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    client = OpenAI(api_key=api_key)
    print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    return client

def basic_chat_completion(client, user_message, model="gpt-4"):
    """ê¸°ë³¸ Chat Completions API í˜¸ì¶œ"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": user_message}
            ],
            temperature=0.7,  # ì°½ì˜ì„± ì¡°ì ˆ (0.0-2.0)
            max_tokens=1000,  # ìµœëŒ€ í† í° ìˆ˜
        )

        return response.choices[0].message.content

    except Exception as e:
        print(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

def sentiment_analysis_example(client):
    """ê°ì„± ë¶„ì„ ì˜ˆì œ"""
    comment = "ì´ ì •ì±…ì€ ì •ë§ ìµœì•…ì´ì—ìš”. ì™„ì „íˆ ì‹¤ë§í–ˆìŠµë‹ˆë‹¤."

    system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ê°ì„± ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³  
    ê·¸ ì´ìœ ë¥¼ ê°„ëµíˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë‹¤ìŒ ëŒ“ê¸€ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {comment}"}
            ],
            temperature=0.3,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
        )

        return response.choices[0].message.content

    except Exception as e:
        print(f"âŒ ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

def compare_models(client, prompt):
    """GPT-4ì™€ GPT-3.5-turbo ë¹„êµ"""
    models = ["gpt-4", "gpt-3.5-turbo"]
    results = {}

    for model in models:
        print(f"\nğŸ”„ {model} ì‘ë‹µ ìƒì„± ì¤‘...")
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=200
            )

            results[model] = response.choices[0].message.content

            # í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ (ê°€ëŠ¥í•œ ê²½ìš°)
            if hasattr(response, 'usage'):
                usage = response.usage
                print(f"  ğŸ“Š í† í° ì‚¬ìš©ëŸ‰: {usage.prompt_tokens} + {usage.completion_tokens} = {usage.total_tokens}")

        except Exception as e:
            results[model] = f"ì˜¤ë¥˜: {e}"

    return results

if __name__ == "__main__":
    print("ğŸš€ OpenAI API ê¸°ì´ˆ ì‹¤ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    print("=" * 50)

    try:
        # 1. OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = setup_openai_client()

        # 2. ê¸°ë³¸ ì±„íŒ… ì˜ˆì œ
        print("\n1ï¸âƒ£ ê¸°ë³¸ ì±„íŒ… ì˜ˆì œ")
        print("-" * 30)
        user_input = "AI ì—ì´ì „íŠ¸ë€ ë¬´ì—‡ì¸ê°€ìš”?"
        response = basic_chat_completion(client, user_input)
        if response:
            print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_input}")
            print(f"ğŸ¤– GPT-4: {response}")

        # 3. ê°ì„± ë¶„ì„ ì˜ˆì œ
        print("\n2ï¸âƒ£ ê°ì„± ë¶„ì„ ì˜ˆì œ")
        print("-" * 30)
        sentiment_result = sentiment_analysis_example(client)
        if sentiment_result:
            print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼:\n{sentiment_result}")

        # 4. ëª¨ë¸ ë¹„êµ ì˜ˆì œ
        print("\n3ï¸âƒ£ GPT-4 vs GPT-3.5-turbo ë¹„êµ")
        print("-" * 30)
        comparison_prompt = "Multi-Agent ì‹œìŠ¤í…œì˜ ì¥ì ì„ 3ê°€ì§€ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."
        comparison_results = compare_models(client, comparison_prompt)

        for model, result in comparison_results.items():
            print(f"\nğŸ”¹ {model.upper()}:")
            print(result)

        print("\nâœ… ì‹¤ìŠµ ì™„ë£Œ!")
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print("   - 02_gemini_basic.py: Google Gemini API ì‹¤ìŠµ")
        print("   - 03_prompt_engineering.py: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§")

    except Exception as e:
        print(f"âŒ ì „ì²´ ì‹¤ìŠµ ì˜¤ë¥˜: {e}")
        print("\nğŸ”§ í•´ê²° ë°©ë²•:")
        print("   1. .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì • í™•ì¸")
        print("   2. pip install openai python-dotenv")
        print("   3. API í‚¤ ìœ íš¨ì„± ë° í¬ë ˆë”§ ì”ì•¡ í™•ì¸")
